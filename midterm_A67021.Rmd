---
title: "mideterm R A67021"
output: html_notebook
---
# 0. Packages
```{r}
library(tidyverse)
```
# <수치 예측 목적의 머신러닝 기법 적용>
## 1. 다중 회기 분석
```{r}
#. 데이터를 준비하고 변수를 진단하기
library(MASS)
Boston
Boston %>%
  diagnose_numeric() 
```
```{r}
#. 훈련용 데이터와 검증용 데이터를 나누기
set.seed(123) # 재연성을 확보하기 위해 설정함

split <- initial_split(Boston, prop = 0.70)
boston_train <- training(split)
boston_test <- testing(split)
```

```{r}
#. 다중회기분석 기법의 적용
lm_fit <- lm(medv ~., data = boston_train)
#. R4.2.X 버전 이후 기본 모델 리포트가 간소화되어 lm_fit$fit을 지정하여 살펴봅니다.
summary(lm_fit)
glance(lm_fit)
```
```{r}
#. step 함수를 이용한 변수 선택
lm_fit_step <- step(lm_fit, method = "both")
summary(lm_fit_step)
```


```{r}
par(mfrow=c(2,2))
plot(lm_fit$fit,
     pch = 16,
     col = "orange")
```

## 2. 의사결정트리 기법 사용
### ㅏ library: tree를 사용한 의사결정트리
```{r}
#. library: tree
#. parsnip package의 decision_tree()는 tree 패키지 엔진을 지원하지 않는다
library(tree)
tree_fit <- tree(medv ~., data = boston_train)
summary(tree_fit)
```
`
```{r}
# tree model 시각화
plot(tree_fit)
text(tree_fit, pretty = 0)
```

```{r}
#. boston_test를 이용한 예측 결과 생성
tree_yhat <- predict(tree_fit, newdata = boston_test)
mean((tree_yhat - boston_test$medv)^2) #. MSE
```


### ㅏ rpart를 사용한 의사결정나무
```{r}
library(rpart)
#fit Decision Tree nodel
rpart_fit <- rpart(medv ~., data = boston_train)

summary(rpart_fit)
```
```{r}
#. rpart.plot 패키지를 활용한 시각화
library(rpart.plot)
rpart.plot(rpart_fit)
```
```{r}
#. boston_test를 이용한 예측 결과 생성
rpart_yhat <- predict(rpart_fit, newdata = boston_test)
mean((rpart_yhat - boston_test$medv)^2) #. MSE
```

## 3. 인공신경망 기법 사용    
### ㅏ 변수 정규화
```{r}
#. min-max 정규화 함수의 작성
minmax_norm <- function(x){
  return((x-min(x))/(max(x)-min(x)))
}

#. Boston data 의 수치형 변수들을 min-max 정규화
boston_train_norm <- as_tibble(sapply(boston_train, minmax_norm))
boston_test_norm <- as_tibble(sapply(boston_test, minmax_norm))
```
### ㅏ nnet을 사용한 인공신경망 분석
```{r}
library(nnet)
#. 인공신경망 적합
nnet_fit <- nnet(medv ~., data = boston_train_norm, size = 5)
nnet_yhat <- predict(nnet_fit, newdata = boston_test_norm, type = "raw")
mean((nnet_yhat - boston_test_norm$medv)^2) #. MSE
```
### ㅏ neuralnet을 사용한 인공신경망 분석
```{r}
library(neuralnet)
#. 인공신경망 적합
neural_fit <- neuralnet(medv ~. 
                          , data = boston_train_norm, hidden = 5)
#. 예측결과의 생성
neural_result <- compute(neural_fit, boston_test_norm[1:13])
neural_yhat <- neural_result$net.result
mean((neural_yhat - boston_test_norm$medv)^2) #. MSE
```
```{r}
plot(neural_fit)
```

## 4. 앙상블 기법(랜덤포레스트 기법) 사용
```{r}
library(randomForest)

set.seed(1)
rf_fit <- randomForest(formula = medv ~., data = boston_train, mtry = 6,
                       importancee = TRUE)
rf_fit
```
```{r}
#. 랜덤으로 생성되는 tree 갯수에 따른 오류 추이: 100개 이상에선 안정화된다.
plot(rf_fit)
```
```{r}
#. 변수중요도
importance(rf_fit)
varImpPlot(rf_fit)
```
```{r}
rf_yhat <- predict(rpart_fit, newdata = boston_test)
mean((rf_yhat - boston_test$medv)^2) #. MSE
```

# <자율학습 모델 적용하기>
## 1. 클러스터링(군집) 분석 K-means Cluster
```{r}
#. data
iris
```
```{r}
#.목표변수 Species 제외
dt_iris_kmeans <- iris %>% select(c(1:4))
dt_iris_kmeans
```
```{r}
km_out_withinss <- c()
km_out_between <- c()
for(i in 2:7){
  set.seed(1)
  km_out <- kmeans(dt_iris_kmeans, centers = i)
  km_out_withinss[i-1] <- km_out$tot.withinss
  km_out_between[i-1] <- km_out$betweenss
}
#. 두 벡터를 단순히 합칠 경우 행 이름이 없어 오류가 나는 경우가 있다. 이때 대안으로 쓸 수 있는 함수가 expand.grid9)
dt_kmeans <- expand.grid(km_out_withinss, km_out_between)
colnames(dt_kmeans) <- c("km_out_withinss", "km_out_between")
dt_kmeans
```

```{r}
km_out_k3 <- kmeans(dt_iris_kmeans, centers = 3)
as_tibble(km_out_k3$centers) #. 각 군집의 중심점
km_out_k3$cluster #. 각 관측치에 할당된 군집
as_tibble(km_out_k3$size) #.각 군집 데이터의 관측치 개수

#. kmeans cluster와 iris Species를 각각 데이터프레임으로 만들어 둘을 합쳐 새 데이터프레임 생성
dt_cluster_km3 <- as_tibble(km_out_k3$cluster)
dt_species_iris <- as_tibble(iris$Species)
dt_out_kmeans3 <- bind_cols(dt_species_iris, dt_cluster_km3)
colnames(dt_out_kmeans3) <- c("Species", "cluster")
#. 군집 결과
table(dt_out_kmeans3$cluster, iris$Species)
```
```{r}
#. dt_out_kmeans3를 Species, cluster별로 집계하고 와이드 폼으로 cluster와Species의 매트릭스를 생성
dt_out_kmeans3 %>%
  mutate(cnt = 1) %>%
  group_by(Species, cluster) %>%
  summarise(cnt = sum(cnt)) %>%
  pivot_wider(names_from = Species,
              values_from = cnt) %>%
  arrange(cluster) %>%
  mutate_each(funs(replace(., is.na(.), 0)))
```

```{r}
plot(dt_iris_kmeans[ ,1:2], col = km_out_k3$cluster,
     pch = ifelse(km_out_k3$cluster == "1", 16,
                  ifelse(km_out_k3$cluster == "2", 17, 18)), cex = 1) ; 
points(km_out_k3$clusters, col = 1:3, pch = 16:18, cex = 10)
```
## 2. 차원축소 기법 PCA
```{r}
#. data
USArrests
```
```{r}
#. 주성분분석을 하고 결과 출력
pc1 <- princomp(USArrests, cor = TRUE)
summary(pc1)
plot(pc1)
```
```{r}
pc1$center
pc1$scale
pc1$loadings
```

```{r}
as.data.frame(pc1$scores)
```
```{r}
#. 주성분 분석 산포도
plot(pc1$scores[ ,1], pc1$scores[ ,2], xlab = "Z1", ylab = "Z2")
abline(v = 0, h = 0, col = "gray")
```
```{r}
#. 행렬도 기법
biplot(pc1, cex = 0.5)
abline(v = 0, h = 0, col = "gray")
```
## 3. 연관성 분석(장바구니 분석)
```{r}
#. packages
library(arules)
library(arulesViz)
#. data
data(Groceries)
```

```{r}
data(package = "arules")
```

```{r}
#. Groceries data 확인
Groceries
inspect(Groceries[1:10])
```

```{r}
#. 데이터 내 각 아이템의 빈도 확인
summary(Groceries)
```
```{r}
#. 아이템별 빈도 수 : 절대값
sort(itemFrequency(Groceries, type = "absolute"), decreasing = TRUE)
```
```{r}
#. 아이템별 빈도 수 : 상대값
round(sort(itemFrequency(Groceries, type = "relative"), decreasing = TRUE), 3)
```
```{r}
#. 시각화
itemFrequencyPlot(Groceries, topN = 10, type = "absolute")
itemFrequencyPlot(Groceries, topN = 10, type = "relative")
```
```{r}
#.  연과성 분석 수행
#. 지지도 및 신뢰도 미지정 분석
apriori(Groceries) 
```
```{r}
result_rules <- apriori(Groceries, parameter = list(support = 0.005, confidence = 0.5,
                                                    minlen = 2))
```
```{r}
#.  생성된 연관규칙 확인
summary(result_rules)
```
```{r}
#. 규칙 내용 확인
inspect(result_rules[1:5])
```
```{r}
#. 향상도(lift)에 따른 내림차순 정리
rules_lift <- sort(result_rules, by = "lift", decreasing = TRUE)
inspect(rules_lift)

#. 신뢰도(confidence)에 따른 내림차순 정리
rules_conf <- sort(result_rules, by = "confidence", decreasing = TRUE)
inspect(rules_conf)
```
```{r}
#. 관심 아이템에 대한 부분집합 규칙 탐색
rules_milk <- subset(rules_lift, items %in% "whole milk")
rules_milk

inspect(rules_milk[1:5])
```
```{r}
#. 결과(rhs)에서만 whole milk가 나타나는 경우 탐색
rules_milk_rhs <- subset(rules_lift, rhs %in% "whole milk")
rules_milk_rhs
inspect(rules_milk_rhs)
```
```{r}
#. whole milk가 결과로 나타나는 세분화된 연과 규칙 탐색
rules_wholemilk <- apriori(Groceries, parameter = list(support = 0.005, confidence = 0.5,minlen = 2),
                           appearance = list(default = "lhs", rhs = "whole milk"))
rules_wholemilk <- sort(rules_wholemilk, by = "lift", decreasing = TRUE)
inspect(rules_wholemilk)
```
```{r}
#. 연과성 분석 시각화
library(arulesViz)
plot(rules_wholemilk[1:10], method = "graph", measure = "lift", shading = "confidence")
```

# <모델성능 평가하기>
## 1. 여러 모델 성능의 비교 평가
```{r}
#. data
iris
```
```{r}
library(caret)
#. split data
set.seed(123)
idx <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
iris_train <- iris[idx, ]
iris_test <- iris[-idx, ]
table(iris_train$Species)
table(iris_test$Species)
```
```{r}
#. 평가용 모델을 위한 라이브러리 불러오기
library(rpart) #. 의사결정트리
library(e1071) #. 나이브베이즈
library(randomForest) #. 랜덤포레스트
#. 각 모형의 접합
fit_iris_rpart <- rpart(Species~., data = iris_train)
fit_iris_nb    <- naiveBayes(Species~., data = iris_train)
fit_iris_rf    <- randomForest(Species~., data = iris_train, importance = TRUE)
#. 예측 범주값 벡터의 생성
pred_iris_rpart <- predict(fit_iris_rpart ,newdata = iris_test, type = "class")
pred_iris_nb    <- predict(fit_iris_nb, newdata = iris_test, type = "class")
pred_iris_rf    <- predict(fit_iris_rf, newdata = iris_test, type = "response")
```

```{r}
#. simple confusin matrix
table(iris_test$Species, pred_iris_rpart)
table(iris_test$Species, pred_iris_nb)
table(iris_test$Species, pred_iris_rf)
```


```{r}
#. confusion matrix
#. caret의 confusionMatrix 함수를 사용
caret::confusionMatrix(pred_iris_rpart, iris_test$Species, positive = "versicolor")
caret::confusionMatrix(pred_iris_nb, iris_test$Species, positive = "versicolor")
caret::confusionMatrix(pred_iris_rf, iris_test$Species, positive = "versicolor")
```


















